---
output:
  word_document: default
  html_document: default
---
要安装gvlma包，car包，glmnet包，psych包, pls包，boot包

```{r, echo=FALSE}
library(gvlma)
library(car)
library(glmnet)
library(psych)
library(pls)
library(boot)
```


首先我们读入数据：
```{r}
data.raw <- read.csv(file = "../../Data/BodyFat.csv")
#remove IDNO, which is useless. we keep density for data redundancy
data.raw <- data.raw[, -1]
```


用str函数可以查看data各列的数据类型
```{r}
str(data.raw)
```
可以看到除了年龄为整数型随机变量外，其他变量都为浮点型。 没有明显的因子型随机变量。

我们可以先画出因变量对各个自变量的散点图进行探索性分析：
```{r}
par(mfrow = c(2,2))
name = colnames(data.raw)
for(i in 1:15)
{
  plot(x = data.raw[,i + 1], y = data.raw[,1], xlab = name[i+1], ylab = name[1])
}

#is adiposity BMI or BAI?
plot(x = data.raw[,"ADIPOSITY"], y = data.raw[,"HIP"])
plot(x = data.raw[,"ADIPOSITY"], y = data.raw[,"HEIGHT"])
plot(x = data.raw[,"ADIPOSITY"], y = data.raw[,"WEIGHT"])
```
从各散点图中可以看出BODYFAT与多个自变量有着近似线性关系，所以可以首先尝试建立线性模型。某些自变量对BODYFAT的散点图近似有相同趋势提示我们在建立线性模型中可能存在多重共线性的问题。同时散点图中一些点与其他点偏离较大提示数据中可能存在异常点。另外，注意到年龄这一整数型变量与BODYFAT也有着近似线性的趋势，提示我们可以不把年龄变量作为因子型变量。


下面， 我们首先尝试建立BODYFAT对于其他自变量的多元线性回归模型，查看其效果：

```{r}
model.raw <- lm(BODYFAT ~ ., data = data.raw)
summary(model.raw)
par(mfrow = c(2,2))
plot(model.raw)
```
结果显示调整R方的值为0.7298较大，残差图没有明显趋势，正态qq图没有明显问题，但是后两个图形显示模型中存在异常点说明需要去除数据中的异常点。多个自变量不显著说明我们可能需要进行变量选择。我们可以检验模型中是否存在多重共线性：
```{r}
require(car)
vif(model.raw)
```

我们发现模型中存在着严重的多重共线性问题。多重共线性的存在不会影响异常值点的诊断，我们可以首先去掉异常点。第182行数据BODYFAT为0显然错误，需要去除。 标准化残差图和residual vs leverage图显示了多个异常点和高杠杆点， Cook's D显示第四十二个点为强影响点。强影响点存在时一次去除多个点可能造成错误去除，我们先去掉点42和182之后再次拟合模型：

```{r}
data.raw2 <- data.raw[-c(42, 182),]
model.raw2 <- lm(BODYFAT ~ ., data = data.raw2)
par(mfrow = c(2,2))
plot(model.raw2)
```
点39近似为强影响点，去除后再次建立模型：
```{r}
data.raw3 <- data.raw[-c(39, 42, 182),]
model.raw3 <- lm(BODYFAT ~ ., data = data.raw3)
par(mfrow = c(2,2))
plot(model.raw3)
```
现在不再有明显的强影响点，标准化残差图显示没有明显的离群点，但是标准化残差vs杠杆值图显示存在不少高杠杆值点，我们用帽矩阵法去除强影响点。我们定义下面的函数来画出帽矩阵值及对应的点的序号：

```{r}
hat.plot <- function(fit){
  p <- length(coefficients(fit))
  n <- length(fitted(fit))
  plot(hatvalues(fit),main = "Index Plot of Hat Values")
  abline(h=c(2,3)*p/n,col="red",lty=2)
  identify(1:n, hatvalues(fit), names(hatvalues(fit)))  
  #这句产生交互效果，选中某个点后，关闭后返回点的名称
}
```

寻找高杠杆点：
```{r}
hat.plot(model.raw3)
```
发现高杠杆点为31, 36, 41, 54, 86, 106, 159, 163, 175, 206, 216, 221，去除这些高杠杆点再次建立模型：


```{r}
data.raw4 <- data.raw[-c(39, 182, 42, 31, 36, 41, 54, 86, 106, 159, 163, 175, 206, 216, 221),]
model.raw4 <- lm(BODYFAT ~ ., data = data.raw4)
par(mfrow = c(2,2))
plot(model.raw4)
```
可以看到model.raw3中明显的高杠杆值点被去除了，再检验一下高杠杆值点：
```{r}
hat.plot(model.raw4)
```
5, 74, 96, 172, 240, 242为高杠杆值点但程度不大，精确起见我们还是将它们去除：
```{r}
data.raw5 <- data.raw[-c(39, 182, 42, 31, 36, 41, 54, 86, 106, 159, 163, 175, 206, 216, 221, 5, 74, 96, 172, 240, 242),]
model.raw5 <- lm(BODYFAT ~ ., data = data.raw5)
par(mfrow = c(2,2))
plot(model.raw5)
par(mfrow = c(1,1))
hat.plot(model.raw5)
```
现在没有明显的离群点，也没有强影响点和高杠杆值点了。总结一下，182为错误数据，点39，42为强影响点，点5, 31, 36, 41, 54, 74, 86, 96, 106, 159, 163, 172, 175, 206, 216, 221, 240, 242为高杠杆值点。我们去掉这些异常点，将剩下的清洗后的数据导入变量data, 用清洗后的数据建立多元线性模型(实际上就是model.raw5):

```{r}
data <- data.raw5
model <- lm(BODYFAT ~ ., data = data)
summary(model)
par(mfrow = c(2,2))
plot(model)
```

可以看出调整R方仍然比较大，残差图没有明显趋势，模型假设中独立性，线性性，方差齐性比较好的满足了，也不再有明显的异常点，但是正态性假设似乎稍有违背，但是残差分布似乎是对称的并且偏离正态分布的程度不大。 我们用R语言实战第八章中提供的各个函数对上述的各个论断进行严格的检验：

独立性假定：
```{r}
durbinWatsonTest(model)
```
Durbin-Watson检验的p值大于0.05，说明独立性假定满足。

同方差性假定：
```{r}
ncvTest(model)
```
计分检验p值非常高，说明同方差性假定满足。

线性性假定以及误差项的偏度，峰度与正态偏度峰度相近的检验（所用函数在中文版R语言实战第181页）：
```{r}
require(gvlma)
gvmodel <- gvlma(model)
summary(gvmodel)
```
结果显示线性性假定满足，同时误差项的分布为对称分布，且峰度与正态分布的峰度近似，其分布与正态分布比较相近。

正态性检验：
```{r}
shapiro.test(model$residuals)
```
Shapiro-Wilk normality test显示正态性假定未满足，但是p值不是特别大，说明偏离程度比较低。我们先尝试对BODYFAT数据进行box-cox变换：

```{r}
require(car)
summary(powerTransform(data$BODYFAT))
```

函数结果显示选取幂次0.85对BODYFAT数据进行变换并拟合模型。
```{r}
model.trans <- lm(BODYFAT^0.85 ~ ., data = data)
summary(model.trans)
par(mfrow = c(2,2))
plot(model.trans)
shapiro.test(model.trans$residuals)
```
我们发现box-cox变换很厉害然而并没有什么卵用。但是我们可以论述用模型model也是合理的：在线性回归分析中我们证明过，当独立性假定，线性性假定，同方差性假定满足，并且误差项分布为对称分布且与正态分布比较相近时，线性回归模型依然是稳健的，故我们仍然可以用模型model。


下面我们还需要处理多重共线性问题。我们考虑三种不同的方法：1.lasso regression做变量选择， 2.主成分分析 3.偏最小二乘。

1.lasso regression做变量选择
首先我们考虑lasso regression模型，用glmnet包（lasso法发明人写的包），介绍在https://cosx.org/2016/10/data-mining-1-lasso/。 cv.glmnet用交叉验证方法选出合理的lambda值以及对应的变量。
```{r}
require(glmnet)
y = as.matrix(data[,1])
x = as.matrix(data[,-1])
fit = cv.glmnet(x = x, y = y, family = "gaussian", nlambda = 100, alpha = 1, standardize=TRUE, nfolds = 10)
print(fit$lambda.1se)
print(log(fit$lambda.1se))
plot(fit)
```
每次运行cv.glmnet时得到的结果是不一样的，上面只显示了一次的结果，多次重复后发现保留三到四个变量是合理的。下面我们确定保留哪些变量：
```{r}
fit2 = glmnet(x = x, y = y, family = "gaussian", nlambda = 100, alpha = 1, standardize=TRUE)
plot(fit2, xvar = "lambda", label = TRUE)
print(fit2$jerr)
```
可以看到第1， 3， 7， 14个自变量被保留，我们把相应的数据存入data.lasso中并拟合模型：
```{r}
data.lasso <- data[,c(1, 2, 4, 8, 15)]
model.lasso <- lm(BODYFAT ~., data = data.lasso)
summary(model.lasso)
plot(model.lasso)
vif(model.lasso)
```
可以看到调整R方为0.6974与保留所有自变量时相差不大，但是年龄变量在0.05显著性下不显著。各个图形显示模型的各项假定除了正态性假定仍有轻微偏离以外其他假定都很好的满足了。方差膨胀因子足够小，多重共线性问题解决了。注意lasso并不保证选出最优模型，我们去掉HEIGHT变量替换为WEIGHT变量后发现AGE不再显著，再去掉AGE变量后发现调整R方更大了，而方差膨胀因子仍然不大。我们也将这个模型作为一个备选：

```{r}
data.lasso.adjusted <- data[,c(1, 3, 8, 15)]
model.lasso.adjusted <- lm(BODYFAT ~., data = data.lasso.adjusted)
summary(model.lasso.adjusted)
plot(model.lasso.adjusted)
vif(model.lasso.adjusted)
```

2.主成分分析：
对数据标准化以便建立主成分分析模型：
```{r}
data.scaled <- as.data.frame(scale(data, center = TRUE, scale = TRUE))
```

下面考虑主成分分析模型，所用函数介绍在R语言实战第十四章：
```{r}
require(psych)
```

fa.parallel函数可以确定主成分的个数,所画出的碎石图同时显示了三种选择主元素个数的准则：
```{r}
fa.parallel(data.scaled[,-1], fa = "pc", n.iter = 1000, show.legend = FALSE, main = "Scree plot with parallel analysis")
```
准则显示我们可以选择保留二个主成分。保留三个主成分也是合理的，我们可以将保留二个或三个主成分的主成分分析模型作为备选。
```{r}
principal(data.scaled[,-1], nfactors = 2, rotate = "none")
principal(data.scaled[,-1], nfactors = 3, rotate = "none")

```


下面用偏最小二乘法建立模型， 调用pls包：
```{r}
require("pls")
```


```{r}
fit.pls <- plsr(BODYFAT~., data=data.scaled, scale=T, validation="CV")
summary(fit.pls)
```

由于每次运行时所得的adjCV的值不一样，经过多次重复后发现我们可以使用2到3个成分。 我们将2到3个成分的偏最小二乘模型作为备选。

下面我们对用三种方法得到的六个备选模型用k-fold交叉验证方法选出最好的模型。依照惯例，k可以选择5或10。为了保证cv得出的结果的数量级一致，我们都用正规化后的数据进行分析（如用调整R方做交叉验证，则不用正规化）：

安装boot包
```{r}
require(boot)

```
对lasso模型用10-fold 交叉验证 100次并计算adjusted cv的平均值：
```{r}
  data.lasso.scaled <- as.data.frame(scale(data.lasso, center = T, scale = T))
cv.err <- rep(0,30)
for(i in 1:30){

  glm.fit <- glm(BODYFAT ~ .,data = data.lasso.scaled)
  cv.err[i] = cv.glm(data.lasso.scaled,glm.fit,K=10)$delta[2]
}
plot(cv.err)
print(mean(cv.err))
```

对主成分分析模型进行交叉检验的函数，n为主成分数
```{r}
get.cv.prin <- function(n)
{
covmatrix <- cov(data.scaled[,-1])
eigen.vector <- eigen(covmatrix)$vectors
eigen.vector.n <- eigen.vector[,1:n]
prin.data.n <- as.matrix(data.scaled[,-1]) %*% eigen.vector.n
data.frame.n <- as.data.frame(cbind(data.scaled[,1], prin.data.n))
cv.err <- rep(0,30)
for(i in 1:30) {
  glm.fit <- glm(V1 ~ V2 + V3, data = data.frame.n)
  cv.err[i] = cv.glm(data.frame.n,glm.fit,K=10)$delta[2]
}
plot(cv.err)
print(mean(cv.err))
}
```


```{r}
get.cv.prin(2)
get.cv.prin(3)
get.cv.prin(4)
get.cv.prin(5)

```
pls的cv在之前已经给出来了，最后发现竟然是lasso优于主成分优于偏最小二乘？我觉得交叉检验这一块有问题做的很不好，先来个初稿把
